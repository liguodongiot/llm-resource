




- Large Language Model Inference Acceleration: A Comprehensive Hardware Perspective：https://arxiv.org/pdf/2410.04466v3


- Low-bit Model Quantization for Deep Neural Networks: A Survey : https://arxiv.org/pdf/2505.05530


- A Survey on Inference Optimization Techniques for Mixture of Experts Models：https://arxiv.org/pdf/2412.14219
