


## LLM推理优化


- LLM Inference Performance Engineering: Best Practices：https://www.databricks.com/blog/llm-inference-performance-engineering-best-practices
- 大语言模型推理性能工程优化最佳实践：https://mp.weixin.qq.com/s?__biz=MzU3Mzg5ODgxMg==&mid=2247486293&idx=1&sn=2b47cbbe189953599e254158fd78a18d&chksm=fd3be206ca4c6b109667e8813623db42a53b7ac0cd628a6cfd57f36334cb53e9ee33d49dd2dc&scene=21#wechat_redirect
- 语言大模型推理性能工程：最佳实践：https://zhuanlan.zhihu.com/p/663282469
- Reproducible Performance Metrics for LLM inference：https://www.anyscale.com/blog/reproducible-performance-metrics-for-llm-inference
- 可复现的语言大模型推理性能指标：https://zhuanlan.zhihu.com/p/667612787
- [从零实现AI推理引擎](https://www.zhihu.com/column/c_1760127081235820544)




### llama.cpp

- [Understanding how LLM inference works with llama.cpp](https://www.omrimallis.com/posts/understanding-how-llm-inference-works-with-llama-cpp/)
- [Llama.cpp 教程：高效 LLM 推理和实现的完整指南](https://blog.csdn.net/weixin_41863029/article/details/139456502)
- [LLM如何通过llama.cpp进行推理](https://blog.csdn.net/Blaze_bxh/article/details/137054444)
- [llama.cpp源码解析](https://mp.weixin.qq.com/s?__biz=MzA4MjY4NTk0NQ==&mid=2247519554&idx=1&sn=c619e9907fb515e88b6265cf7017b726&chksm=9f8337d4a8f4bec27c755148f904668a46c85322e6ba31bc6b0286887bbb30f8a24a49d2d918&mpshare=1&scene=23&srcid=1107jzAJDvx0GcmHJO92iIcA&sharer_shareinfo=3dc56c7e8fdbf855398ab67e34dfb5c7&sharer_shareinfo_first=3dc56c7e8fdbf855398ab67e34dfb5c7#rd)



### vLLM


- [Explaining the Code of the vLLM Inference Engine](https://medium.com/@crclq2018/explaining-the-source-code-behind-the-vllm-fast-inference-engine-91429f54d1f7)
- [vLLM框架原理——PagedAttention](https://zhuanlan.zhihu.com/p/649537608)
- [大模型推理框架 vLLM 源码解析（一）：框架概览](https://zhuanlan.zhihu.com/p/681402162)
- [LLM推理2：vLLM源码学习](https://zhuanlan.zhihu.com/p/643336063)
- [Deploying Multiple Large Language Models with NVIDIA Triton Server and vLLM](https://awslabs.github.io/data-on-eks/docs/gen-ai/inference/vLLM-NVIDIATritonServer-Llama2)





### SGLang


- [sglang 源码学习笔记（一）- Cache、Req与Scheduler](https://zhuanlan.zhihu.com/p/17186885141)
- [从零开始设计SGLang的KV Cache](https://zhuanlan.zhihu.com/p/31160183506)
- [SGLang: Triton加速FP8量化与矩阵乘](https://zhuanlan.zhihu.com/p/16179102081)








